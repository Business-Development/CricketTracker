{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cricket Shot Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMm7wY0GXxp66d0MCMbumMd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anudeepayina/CricketTracker/blob/master/Cricket_Shot_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBC7-EIc3Oy8",
        "colab_type": "text"
      },
      "source": [
        "**Setup**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QO3DHkOR01LP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install google-cloud-automl\n",
        "!apt-get install libmagickwand-dev\n",
        "!pip install pillow\n",
        "!pip install --upgrade protobuf\n",
        "!pip install --upgrade google-cloud-videointelligence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6p4LYsN07AD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import os\n",
        "import json\n",
        "import math\n",
        "\n",
        "from google.colab import auth\n",
        "from google.colab import files\n",
        "\n",
        "import pandas as pd\n",
        "from PIL import Image, ImageDraw\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from google.cloud import automl\n",
        "from google.cloud import videointelligence_v1p3beta1 as videointelligence\n",
        "from google.oauth2 import service_account"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzlfCJMB0_-p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "auth.authenticate_user()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8d5Gy8h1Dp6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: REMOVE MY SPECIFIC CONFIG\n",
        "project_id = 'bodytracker-283617'  #@param {type: \"string\"}\n",
        "bucket = 'gs://cricket_bucket' #@param {type: \"string\"}\n",
        "service_account_name=\"jacksparrow\" #@param {type: \"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riAAcL461Hsm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gcloud config set project {project_id}\n",
        "!gsutil mb {bucket}\n",
        "!gcloud iam service-accounts create {service_account_name}\n",
        "!gcloud iam service-accounts keys create ./key.json --iam-account {service_account_name}@{project_id}.iam.gserviceaccount.com\n",
        "\n",
        "# Enable the Video Intelligence API and AutoML\n",
        "!gcloud services enable videointelligence.googleapis.com\n",
        "!gcloud services enable automl.googleapis.com\n",
        "\n",
        "# Give your service account permission to access the API\n",
        "!gcloud projects add-iam-policy-binding {project_id} --member=\"serviceAccount:{service_account_name}@{project_id}.iam.gserviceaccount.com\" --role=\"roles/editor\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_6W1bN9-hUN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"./key.json\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxWCjm5z3UbL",
        "colab_type": "text"
      },
      "source": [
        "**Run videos through API**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQWTgiE21NvO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create file names for three shots, forward defensive, backfoot defensive and cover drive\n",
        "#Forward defensive\n",
        "obj_fd = {}\n",
        "obj_bd = {}\n",
        "obj_cd = {}\n",
        "numbers = list(range(1,4,1))\n",
        "for index in numbers:\n",
        "  obj_fd[\"test_fd\" + str(index)] = []\n",
        "  obj_bd[\"test_b\" + str(index)] = []\n",
        "  obj_cd[\"test_cd\" + str(index)] = [] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WO3oHLjn1qFY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for keys in obj_fd.keys():\n",
        "  file_to_analyze = keys + \".mp4\" \n",
        "  input_uri = os.path.join(bucket, file_to_analyze)\n",
        "  output_uri = os.path.join(bucket, keys+ '.json')\n",
        "  # This function comes from the docs\n",
        " #https://cloud.google.com/video-intelligence/docs/people-detection\n",
        "  def detect_person(input_uri, output_uri):\n",
        "      \"\"\"Detects people in a video.\"\"\"\n",
        "\n",
        "      client = videointelligence.VideoIntelligenceServiceClient(credentials=service_account.Credentials.from_service_account_file(\n",
        "      './key.json'))\n",
        "\n",
        "      # Configure the request\n",
        "      config = videointelligence.types.PersonDetectionConfig(\n",
        "          include_bounding_boxes=True,\n",
        "          include_attributes=True,\n",
        "          include_pose_landmarks=True,\n",
        "      )\n",
        "      context = videointelligence.types.VideoContext(person_detection_config=config)\n",
        "\n",
        "      # Start the asynchronous request\n",
        "      operation = client.annotate_video(\n",
        "          input_uri=input_uri,\n",
        "          output_uri=output_uri,\n",
        "          features=[videointelligence.enums.Feature.PERSON_DETECTION],\n",
        "          video_context=context,\n",
        "      )\n",
        "      return operation\n",
        " \n",
        "  operation = detect_person(input_uri, output_uri)\n",
        "  !mkdir tmp\n",
        "  !gsutil cp {output_uri} tmp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vB0jc1b1zxf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for keys in obj_bd.keys():\n",
        "  file_to_analyze = keys + \".mp4\" \n",
        "  input_uri = os.path.join(bucket, file_to_analyze)\n",
        "  output_uri = os.path.join(bucket, keys+ '.json')\n",
        "  # This function comes from the docs\n",
        " #https://cloud.google.com/video-intelligence/docs/people-detection\n",
        "  def detect_person(input_uri, output_uri):\n",
        "      \"\"\"Detects people in a video.\"\"\"\n",
        "\n",
        "      client = videointelligence.VideoIntelligenceServiceClient(credentials=service_account.Credentials.from_service_account_file(\n",
        "      './key.json'))\n",
        "\n",
        "      # Configure the request\n",
        "      config = videointelligence.types.PersonDetectionConfig(\n",
        "          include_bounding_boxes=True,\n",
        "          include_attributes=True,\n",
        "          include_pose_landmarks=True,\n",
        "      )\n",
        "      context = videointelligence.types.VideoContext(person_detection_config=config)\n",
        "\n",
        "      # Start the asynchronous request\n",
        "      operation = client.annotate_video(\n",
        "          input_uri=input_uri,\n",
        "          output_uri=output_uri,\n",
        "          features=[videointelligence.enums.Feature.PERSON_DETECTION],\n",
        "          video_context=context,\n",
        "      )\n",
        "\n",
        "      return operation\n",
        "  operation = detect_person(input_uri, output_uri)\n",
        "  !mkdir tmp\n",
        "  !gsutil cp {output_uri} tmp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WElW2vSQ2zyq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for keys in obj_cd.keys():\n",
        "  file_to_analyze = keys + \".mp4\" \n",
        "  input_uri = os.path.join(bucket, file_to_analyze)\n",
        "  output_uri = os.path.join(bucket, keys+ '.json')\n",
        "  # This function comes from the docs\n",
        " #https://cloud.google.com/video-intelligence/docs/people-detection\n",
        "  def detect_person(input_uri, output_uri):\n",
        "      \"\"\"Detects people in a video.\"\"\"\n",
        "\n",
        "      client = videointelligence.VideoIntelligenceServiceClient(credentials=service_account.Credentials.from_service_account_file(\n",
        "      './key.json'))\n",
        "\n",
        "      # Configure the request\n",
        "      config = videointelligence.types.PersonDetectionConfig(\n",
        "          include_bounding_boxes=True,\n",
        "          include_attributes=True,\n",
        "          include_pose_landmarks=True,\n",
        "      )\n",
        "      context = videointelligence.types.VideoContext(person_detection_config=config)\n",
        "\n",
        "      # Start the asynchronous request\n",
        "      operation = client.annotate_video(\n",
        "          input_uri=input_uri,\n",
        "          output_uri=output_uri,\n",
        "          features=[videointelligence.enums.Feature.PERSON_DETECTION],\n",
        "          video_context=context,\n",
        "      )\n",
        "\n",
        "      return operation\n",
        "  operation = detect_person(input_uri, output_uri)\n",
        "  !mkdir tmp\n",
        "  !gsutil cp {output_uri} tmp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmgirR0J3h_x",
        "colab_type": "text"
      },
      "source": [
        "**Data Formatting**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRsxqAb-3s03",
        "colab_type": "text"
      },
      "source": [
        "Bring data from the cloud"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoM0KiZj3rtj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "This helper function takes in a person and rearranges the data so it's in \n",
        "a timeline, which will make it easier for us to work with\n",
        "'''\n",
        "def analyzePerson(person):\n",
        "  frames = []\n",
        "  for track in person['tracks']:\n",
        "    # Convert timestamps to seconds\n",
        "    for ts_obj in track['timestamped_objects']:\n",
        "      time_offset = ts_obj['time_offset']\n",
        "      timestamp = 0\n",
        "      if 'nanos' in time_offset:\n",
        "        timestamp += time_offset['nanos'] / 10**9\n",
        "      if 'seconds' in time_offset:\n",
        "        timestamp += time_offset['seconds']\n",
        "      if 'minutes' in time_offset:\n",
        "        timestamp += time_offset['minutes'] * 60\n",
        "      frame= {'timestamp' : timestamp}\n",
        "      for landmark in ts_obj['landmarks']:\n",
        "        frame[landmark['name'] + '_x'] = landmark['point']['x']\n",
        "        # Subtract y value from 1 because positions are calculated\n",
        "        # from the top left corner\n",
        "        frame[landmark['name'] + '_y'] = 1 - landmark['point']['y']\n",
        "      frames.append(frame)\n",
        "  sorted(frames, key=lambda x: x['timestamp'])\n",
        "  return frames"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lzg5GXIy3yQh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "forward_defensive_Pd = pd.DataFrame([])\n",
        "backfoot_defensive_Pd = pd.DataFrame([])\n",
        "cover_drive_Pd = pd.DataFrame([])\n",
        "for keys in obj_fd.keys():\n",
        "  data = json.load(open('./tmp/' + keys + '.json'))\n",
        "  people_annotations = data['annotation_results'][0]['person_detection_annotations']\n",
        "  annotationsPd = pd.DataFrame(analyzePerson(people_annotations[0]))\n",
        "  forward_defensive_Pd = forward_defensive_Pd.append(annotationsPd)\n",
        "for keys in obj_bd.keys():\n",
        "  data = json.load(open('./tmp/' + keys + '.json'))\n",
        "  people_annotations = data['annotation_results'][0]['person_detection_annotations']\n",
        "  annotationsPd = pd.DataFrame(analyzePerson(people_annotations[0]))\n",
        "  backfoot_defensive_Pd = backfoot_defensive_Pd.append(annotationsPd)\n",
        "for keys in obj_cd.keys():\n",
        "  data = json.load(open('./tmp/' + keys + '.json'))\n",
        "  people_annotations = data['annotation_results'][0]['person_detection_annotations']\n",
        "  annotationsPd = pd.DataFrame(analyzePerson(people_annotations[0]))\n",
        "  cover_drive_Pd = cover_drive_Pd.append(annotationsPd)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOvJ0ls6SZ40",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "forward_defensive_Pd[\"left_ear_x\"] = 0\n",
        "forward_defensive_Pd[\"left_ear_y\"] = 0\n",
        "cover_drive_Pd[\"left_ear_x\"] = 0\n",
        "cover_drive_Pd[\"left_ear_y\"] = 0\n",
        "backfoot_defensive_Pd[\"left_ear_x\"] = 0\n",
        "backfoot_defensive_Pd[\"left_ear_y\"] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoivEyLfDHV_",
        "colab_type": "text"
      },
      "source": [
        "Fill \"na\" with zeros"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGEdEMW4OSrV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cover_drive_Pd.fillna(0,inplace=True)\n",
        "forward_defensive_Pd.fillna(0,inplace=True)\n",
        "backfoot_defensive_Pd.fillna(0,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpGoFX64DJ1D",
        "colab_type": "text"
      },
      "source": [
        "Reset index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USXPolRyOWSd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd_test = cover_drive_Pd.reset_index()\n",
        "cd_test.drop(\"index\",axis=1,inplace=True)\n",
        "fd_test = forward_defensive_Pd.reset_index()\n",
        "fd_test.drop(\"index\",axis=1,inplace=True)\n",
        "bd_test = backfoot_defensive_Pd.reset_index()\n",
        "bd_test.drop(\"index\",axis=1,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0cSSxYLiEyh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "66b1943d-fabf-42c5-e68d-24c304f03131"
      },
      "source": [
        "len(cd_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "89"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PvCVBTjDNeI",
        "colab_type": "text"
      },
      "source": [
        "**Split data into each video**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SR6nmqb02kUX",
        "colab_type": "text"
      },
      "source": [
        "First find the index where timestamp is at zero"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Imo4hpuObOY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "453016d2-3025-460e-e530-508f6e42cc90"
      },
      "source": [
        "zero_index_cd = cd_test[cd_test[\"timestamp\"]==0].index.to_list()\n",
        "zero_index_n0_cd =  zero_index_cd[1:] \n",
        "zero_index_n0_cd.append(len(cd_test))\n",
        "zero_index_fd = fd_test[fd_test[\"timestamp\"]==0].index.to_list()\n",
        "zero_index_n0_fd =  zero_index_fd[1:]\n",
        "zero_index_n0_fd.append(len(fd_test))\n",
        "zero_index_bd = bd_test[bd_test[\"timestamp\"]==0].index.to_list()\n",
        "zero_index_n0_bd =  zero_index_bd[1:]\n",
        "zero_index_n0_bd.append(len(bd_test))\n",
        "print(zero_index_bd)\n",
        "print(zero_index_n0_bd)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 23, 45]\n",
            "[23, 45, 67]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Dd4Uq0GOhts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd_test = cd_test.drop(\"timestamp\",axis=1)\n",
        "fd_test = fd_test.drop(\"timestamp\",axis=1)\n",
        "bd_test = bd_test.drop(\"timestamp\",axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYdnydgLrBId",
        "colab_type": "text"
      },
      "source": [
        "Make positional values at each timestamp relative to t = 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_Y-TXFjsOwJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for item, num in zip (zero_index_cd,zero_index_n0_cd):\n",
        "    cd_test.loc[item:num,:] = cd_test.loc[item:num,:] - cd_test.loc[item,:]\n",
        "for item, num in zip (zero_index_bd,zero_index_n0_bd):\n",
        "    bd_test.loc[item:num,:] = bd_test.loc[item:num,:] - bd_test.loc[item,:]\n",
        "for item, num in zip (zero_index_fd,zero_index_n0_fd):\n",
        "    fd_test.loc[item:num,:] = fd_test.loc[item:num,:] - fd_test.loc[item,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hd9EQ7VIRTaZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "398d1f2b-2887-41d4-9d08-32ec978a946b"
      },
      "source": [
        "fd_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(94, 34)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZ-MAD6F20vc",
        "colab_type": "text"
      },
      "source": [
        "Split data up into each video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0Ys7LFdOkrR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cover_drive = {}\n",
        "forward_defensive = {}\n",
        "backfoot_defensive = {}\n",
        "for index, num in zip(zero_index_cd,zero_index_n0_cd):\n",
        "  cover_drive[\"cd_\" + str(index)] = cd_test.iloc[index:num,:]\n",
        "for index, num in zip(zero_index_fd,zero_index_n0_fd):\n",
        "  forward_defensive[\"fd_\" + str(index)] = fd_test.iloc[index:num,:]\n",
        "for index, num in zip(zero_index_bd,zero_index_n0_bd):\n",
        "  backfoot_defensive[\"bd_\" + str(index)] = bd_test.iloc[index:num,:]  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rX6Vog3o2_z0",
        "colab_type": "text"
      },
      "source": [
        "Store into lists"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ga1eg0TtOmow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequence_cd = []\n",
        "sequence_fd = []\n",
        "sequence_bd = []\n",
        "for key in cover_drive:\n",
        "  sequence_cd.append(cover_drive[key].values)\n",
        "for key in forward_defensive:\n",
        "  sequence_fd.append(forward_defensive[key].values)\n",
        "for key in backfoot_defensive:\n",
        "  sequence_bd.append(backfoot_defensive[key].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGFh35WYDSWy",
        "colab_type": "text"
      },
      "source": [
        "Format data so that each has video has equal length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_czks8YAOon9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "7ac9dd52-54b6-4f86-f2a8-39d1c85cf451"
      },
      "source": [
        "len_sequences = []\n",
        "for one_seq in sequence_cd:\n",
        "    len_sequences.append(len(one_seq))\n",
        "pd.Series(len_sequences).hist()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f5c39bab978>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MPnNIFdOs8J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Padding the sequence with the values in last row to max length\n",
        "to_pad = 36\n",
        "new_seq = []\n",
        "for one_seq in sequence_cd:\n",
        "    len_one_seq = len(one_seq)\n",
        "    last_val = one_seq[-1]\n",
        "    n = to_pad - len_one_seq\n",
        "   \n",
        "    to_concat = np.repeat(one_seq[-1], n).reshape(34, n).transpose()\n",
        "    new_one_seq = np.concatenate([one_seq, to_concat])\n",
        "    new_seq.append(new_one_seq)\n",
        "final_seq_cd = np.stack(new_seq)\n",
        "\n",
        "#truncate the sequence to length 24\n",
        "from keras.preprocessing import sequence\n",
        "seq_len = 24\n",
        "final_seq_cd=sequence.pad_sequences(final_seq_cd, maxlen=seq_len, padding='post', dtype='float', truncating='pre')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "er7fkHJxPZon",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Padding the sequence with the values in last row to max length\n",
        "to_pad = 23\n",
        "new_seq = []\n",
        "for one_seq in sequence_bd:\n",
        "    len_one_seq = len(one_seq)\n",
        "    last_val = one_seq[-1]\n",
        "    n = to_pad - len_one_seq\n",
        "   \n",
        "    to_concat = np.repeat(one_seq[-1], n).reshape(34, n).transpose()\n",
        "    new_one_seq = np.concatenate([one_seq, to_concat])\n",
        "    new_seq.append(new_one_seq)\n",
        "final_seq_bd = np.stack(new_seq)\n",
        "#truncate the sequence to length 24\n",
        "from keras.preprocessing import sequence\n",
        "seq_len = 24\n",
        "final_seq_bd=sequence.pad_sequences(final_seq_bd, maxlen=seq_len, padding='post', dtype='float', truncating='pre')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzOW_qTQQpxJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Padding the sequence with the values in last row to max length\n",
        "to_pad = 36\n",
        "new_seq = []\n",
        "for one_seq in sequence_fd:\n",
        "    len_one_seq = len(one_seq)\n",
        "    last_val = one_seq[-1]\n",
        "    n = to_pad - len_one_seq\n",
        "   \n",
        "    to_concat = np.repeat(one_seq[-1], n).reshape(34, n).transpose()\n",
        "    new_one_seq = np.concatenate([one_seq, to_concat])\n",
        "    new_seq.append(new_one_seq)\n",
        "final_seq_fd = np.stack(new_seq)\n",
        "\n",
        "#truncate the sequence to length 24\n",
        "from keras.preprocessing import sequence\n",
        "seq_len = 24\n",
        "final_seq_fd=sequence.pad_sequences(final_seq_fd, maxlen=seq_len, padding='post', dtype='float', truncating='pre')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoXZAf9of_US",
        "colab_type": "text"
      },
      "source": [
        "**Format data for classification**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J58G8TlxRFRs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4ff81cf9-19bb-456e-896c-d54280d9cf62"
      },
      "source": [
        "final_seq_bd = np.array(final_seq_bd)\n",
        "final_seq_cd = np.array(final_seq_cd)\n",
        "final_seq_fd = np.array(final_seq_fd)\n",
        "final_seq_bd.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 24, 34)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYyGn4FtRHiS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_seq_train = np.vstack((final_seq_bd,final_seq_cd,final_seq_fd))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McchapWuaCoq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "537e33b6-5d6d-4fc0-e546-5f504c017cf1"
      },
      "source": [
        "final_seq_train[0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24, 34)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yp-0R5UPanfR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save(\"classify_this\",final_seq_train)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}